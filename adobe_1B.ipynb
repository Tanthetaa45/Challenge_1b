{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdac49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/wine-ml/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pymupdf in /opt/anaconda3/envs/wine-ml/lib/python3.10/site-packages (1.24.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /opt/anaconda3/envs/wine-ml/lib/python3.10/site-packages (from pymupdf) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187d1573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/wine-ml/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74237a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict\n",
    "import json, pathlib, statistics\n",
    "import sys, fitz                               # PyMuPDF\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382dd137",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Span:\n",
    "    text: str\n",
    "    size: float\n",
    "    x0: float; y0: float; x1: float; y1: float\n",
    "\n",
    "@dataclass\n",
    "class Heading:\n",
    "    level: str      # \"Title\" | \"H1\" | \"H2\" | \"H3\"\n",
    "    text:  str\n",
    "    page:  int      # 0-based\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf576e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outline(headings: List[Heading], out_path: pathlib.Path):\n",
    "    if not headings:\n",
    "        raise ValueError(\"No headings found\")\n",
    "    payload = {\n",
    "        \"title\": headings[0].text,\n",
    "        \"outline\": [asdict(h) for h in headings[1:]]   # skip first (title)\n",
    "    }\n",
    "    out_path.write_text(json.dumps(payload, indent=2, ensure_ascii=False))\n",
    "    print(f\" Outline written to → {out_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a687fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics, math, re, fitz\n",
    "SPACE_THRESHOLD = 0.35          # fraction of font-size that still counts as “no space”\n",
    "\n",
    "def collect_lines(doc, max_pages=100, y_tol=2.0):\n",
    "    \"\"\"\n",
    "    Returns list[page] → list[dict(text,size,y0,y1,....)]\n",
    "    1. Groups spans that share (almost) the same baseline.\n",
    "    2. Joins neighbouring spans without inserting a space when the\n",
    "       horizontal gap is smaller than SPACE_THRESHOLD × font-size.\n",
    "    \"\"\"\n",
    "    pages_lines = []\n",
    "    for p in range(min(len(doc), max_pages)):\n",
    "        page = doc.load_page(p)\n",
    "        h    = page.rect.height\n",
    "        # -- raw spans --------------------------------------------------\n",
    "        spans = []\n",
    "        for blk in page.get_text(\"dict\")[\"blocks\"]:\n",
    "            if blk[\"type\"] != 0:\n",
    "                continue\n",
    "            for ln in blk[\"lines\"]:\n",
    "                for sp in ln[\"spans\"]:\n",
    "                    s = sp[\"text\"]\n",
    "                    if s.strip():\n",
    "                        spans.append(dict(text=s,\n",
    "                                          size=sp[\"size\"],\n",
    "                                          x0=sp[\"bbox\"][0],\n",
    "                                          x1=sp[\"bbox\"][2],\n",
    "                                          y0=sp[\"bbox\"][1]))\n",
    "        # -- sort by baseline, left→right --------------------------------\n",
    "        spans.sort(key=lambda r: (round(r[\"y0\"]/y_tol)*y_tol, r[\"x0\"]))\n",
    "        # -- group by baseline -------------------------------------------\n",
    "        groups, cur, cur_y = [], [], None\n",
    "        for r in spans:\n",
    "            if cur_y is None or abs(r[\"y0\"]-cur_y) <= y_tol:\n",
    "                cur.append(r); cur_y = r[\"y0\"]\n",
    "            else:\n",
    "                groups.append(cur); cur = [r]; cur_y = r[\"y0\"]\n",
    "        if cur:\n",
    "            groups.append(cur)\n",
    "        # -- build full line string --------------------------------------\n",
    "        page_lines = []\n",
    "        for g in groups:\n",
    "            g.sort(key=lambda r: r[\"x0\"])\n",
    "            pieces = [g[0][\"text\"]]\n",
    "            for prev, nxt in zip(g, g[1:]):\n",
    "                gap = nxt[\"x0\"] - prev[\"x1\"]\n",
    "                mean_sz = (prev[\"size\"] + nxt[\"size\"]) / 2\n",
    "                if gap > SPACE_THRESHOLD * mean_sz:\n",
    "                    pieces.append(\" \")\n",
    "                pieces.append(nxt[\"text\"])\n",
    "            txt = \"\".join(pieces).strip()\n",
    "            if not txt:\n",
    "                continue\n",
    "            page_lines.append(dict(text=txt,\n",
    "                                   size=statistics.mean(r[\"size\"] for r in g),\n",
    "                                   y0=min(r[\"y0\"] for r in g)))\n",
    "        pages_lines.append(page_lines)\n",
    "    return pages_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cad5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL   = re.compile(r\"(https?://|www\\.)\\S+\", re.I)\n",
    "_EMAIL = re.compile(r\"\\b\\S+@\\S+\\.\\S+\\b\")\n",
    "_PHONE = re.compile(r\"\\b\\d[\\d\\s\\-]{7,}\\d\\b\")\n",
    "_DASH  = re.compile(r\"[-_]{4,}\")\n",
    "\n",
    "def is_sentence_like(t: str) -> bool:\n",
    "    if _URL.search(t) or _EMAIL.search(t) or _PHONE.search(t):\n",
    "        return False\n",
    "    if _DASH.fullmatch(t.strip(\"-_ \")):\n",
    "        return False\n",
    "    if len(t) < 3:\n",
    "        return False\n",
    "    alpha = sum(c.isalpha() for c in t) / len(t)\n",
    "    return alpha >= 0.40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0528f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_levels(pages_lines, keep_h4=True):\n",
    "    # ­-- body font ----------------------------------------------------------------\n",
    "    body_sz = statistics.median(l[\"size\"] for pg in pages_lines for l in pg)\n",
    "\n",
    "    def cat(sz):\n",
    "        r = sz / body_sz\n",
    "        if   r >= 1.8:  return \"H1\"\n",
    "        elif r >= 1.45: return \"H2\"\n",
    "        elif r >= 1.20: return \"H3\"\n",
    "        elif r >= 1.05 and keep_h4: return \"H4\"\n",
    "        return None\n",
    "\n",
    "    headings = []\n",
    "\n",
    "    # ­-- pick “Title” only if the largest line is in the top 33 % of page-0 -------\n",
    "    top_lines = [l for l in pages_lines[0] if l[\"y0\"] < 0.33 * 792]  # 792 = US-letter-pts\n",
    "    if top_lines:\n",
    "        title_line = max(top_lines, key=lambda l: l[\"size\"])\n",
    "        if is_sentence_like(title_line[\"text\"]):\n",
    "            headings.append(Heading(\"Title\", title_line[\"text\"], 0))\n",
    "\n",
    "    # ­-- all headings -------------------------------------------------------------\n",
    "    for pi, lines in enumerate(pages_lines):\n",
    "        for l in lines:\n",
    "            if not is_sentence_like(l[\"text\"]):                  continue\n",
    "            lvl = cat(l[\"size\"])\n",
    "            if not lvl or len(l[\"text\"].split()) > 40:           continue\n",
    "            if headings and headings[-1].text == l[\"text\"]:      continue\n",
    "            headings.append(Heading(lvl, l[\"text\"], pi))\n",
    "    return headings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d783f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "def extract_outline(pdf_path: str, max_pages: int = 50) -> Dict:\n",
    "    doc         = fitz.open(pdf_path)\n",
    "    pages_lines = collect_lines(doc, max_pages)\n",
    "    heads       = decide_levels(pages_lines)\n",
    "\n",
    "    # No headings at all?\n",
    "    if not heads:\n",
    "        return {\"title\": \"\", \"outline\": []}\n",
    "\n",
    "    # Case A: exactly one Heading, and it's marked as Title\n",
    "    if len(heads) == 1 and heads[0].level == \"Title\":\n",
    "        single = heads[0]\n",
    "        return {\n",
    "            \"title\": \"\",\n",
    "            \"outline\": [\n",
    "                {\"level\": \"H1\", \"text\": single.text, \"page\": single.page}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # Case B: first element is a real Title, rest are outline\n",
    "    if heads[0].level == \"Title\":\n",
    "        title_text = heads[0].text\n",
    "        items = [asdict(h) for h in heads[1:]]\n",
    "    else:\n",
    "        # No Title—everything is outline\n",
    "        title_text = \"\"\n",
    "        items = [asdict(h) for h in heads]\n",
    "\n",
    "    return {\"title\": title_text, \"outline\": items}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da0c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"\",\n",
      "  \"outline\": [\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"Share\",\n",
      "      \"page\": 1\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"PDF sharing options\",\n",
      "      \"page\": 1\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Send an anonymous or public link in an email\",\n",
      "      \"page\": 3\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Mark up text\",\n",
      "      \"page\": 5\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"Highlight, strikethrough, or underline text\",\n",
      "      \"page\": 6\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"comment\",\n",
      "      \"page\": 6\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Using Select Text Tool\",\n",
      "      \"page\": 6\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Using Markup Tool\",\n",
      "      \"page\": 6\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Change the color of the markup\",\n",
      "      \"page\": 7\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Delete The Markup\",\n",
      "      \"page\": 7\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Add a comment to the markup\",\n",
      "      \"page\": 7\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Replace text\",\n",
      "      \"page\": 7\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Insert text\",\n",
      "      \"page\": 8\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Export text edits\",\n",
      "      \"page\": 9\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Share a PDF for review\",\n",
      "      \"page\": 9\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Send an anonymous or public link in an email\",\n",
      "      \"page\": 9\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Reviewer experience\",\n",
      "      \"page\": 10\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Send personalized invitations for commenting\",\n",
      "      \"page\": 10\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Initiate a review using @mention in a PDF\",\n",
      "      \"page\": 11\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Reviewer experience\",\n",
      "      \"page\": 11\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Hosting a shared review on SharePoint or Office 365\",\n",
      "      \"page\": 11\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"Initiate SharePoint-based shared review\",\n",
      "      \"page\": 13\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"using Acrobat\",\n",
      "      \"page\": 13\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pdf_file = \"/Users/tanmayrath/Downloads/Learn Acrobat - Share_1.pdf\"\n",
    "outline  = extract_outline(pdf_file)\n",
    "print(json.dumps(outline, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f79026",
   "metadata": {},
   "source": [
    "**The section from down here is not important pls ignore.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06def691",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q PyMuPDF==1.24.1 pdf2image==1.17.0 Pillow tqdm numpy\n",
    "\n",
    "# (optional, later) pip install -q torch transformers datasets\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import statistics, pathlib, json\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18af479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Line:\n",
    "    text: str\n",
    "    size: float\n",
    "    y0: float\n",
    "\n",
    "@dataclass\n",
    "class Heading:\n",
    "    level: str   # Title | H1 | H2 | H3 | H4...\n",
    "    text: str\n",
    "    page: int    # 1-based\n",
    "\n",
    "def save_outline(outline: Dict, pdf_path: str):\n",
    "    out_path = pathlib.Path(pdf_path).with_suffix(\"_outline.json\")\n",
    "    out_path.write_text(json.dumps(outline, indent=2, ensure_ascii=False))\n",
    "    print(\"✅  Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f041f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_lines(doc: fitz.Document, max_pages: int = 50, y_tol: float = 1.5):\n",
    "    pages = []\n",
    "    for p in range(min(len(doc), max_pages)):\n",
    "        raw = []\n",
    "        page = doc.load_page(p)\n",
    "        for blk in page.get_text(\"dict\")[\"blocks\"]:\n",
    "            if blk[\"type\"] != 0: continue\n",
    "            for ln in blk[\"lines\"]:\n",
    "                for sp in ln[\"spans\"]:\n",
    "                    t = sp[\"text\"].strip()\n",
    "                    if not t: continue\n",
    "                    raw.append((sp[\"bbox\"][1], t, sp[\"size\"]))\n",
    "        # sort by baseline y0 (top→down)\n",
    "        raw.sort(key=lambda x: x[0])\n",
    "        # group into lines\n",
    "        lines = []\n",
    "        curr_y = None\n",
    "        curr_txt = []\n",
    "        curr_szs = []\n",
    "        for y0, txt, sz in raw:\n",
    "            if curr_y is None or abs(y0 - curr_y) <= y_tol:\n",
    "                curr_txt.append(txt)\n",
    "                curr_szs.append(sz)\n",
    "                curr_y = y0\n",
    "            else:\n",
    "                lines.append(Line(\n",
    "                    text=\" \".join(curr_txt),\n",
    "                    size=statistics.mean(curr_szs),\n",
    "                    y0=curr_y\n",
    "                ))\n",
    "                curr_txt = [txt]\n",
    "                curr_szs = [sz]\n",
    "                curr_y = y0\n",
    "        if curr_txt:\n",
    "            lines.append(Line(text=\" \".join(curr_txt),\n",
    "                              size=statistics.mean(curr_szs),\n",
    "                              y0=curr_y))\n",
    "        pages.append(lines)\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913d7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_outline(pdf_path: str, max_pages: int = 50) -> Dict:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = collect_lines(doc, max_pages)\n",
    "\n",
    "    # 1) Extract multi-line Title from page 1\n",
    "    first = pages[0]\n",
    "    if not first:\n",
    "        raise ValueError(\"Page 1 empty\")\n",
    "    max_size = max(ln.size for ln in first)\n",
    "    # take all lines ≥ 90% of max_size\n",
    "    title_lines = [ln for ln in first if ln.size >= 0.9 * max_size]\n",
    "    # sort by y0 (top→down) and join\n",
    "    title_lines.sort(key=lambda ln: ln.y0)\n",
    "    title_text = \" \".join(ln.text for ln in title_lines).strip()\n",
    "\n",
    "    # remove them from the page so they don't reappear as H1\n",
    "    y_set = {ln.y0 for ln in title_lines}\n",
    "    pages[0] = [ln for ln in first if ln.y0 not in y_set]\n",
    "\n",
    "    # 2) Build size ratios relative to BODY\n",
    "    all_sizes = [ln.size for pg in pages for ln in pg]\n",
    "    body_sz   = statistics.median(all_sizes)\n",
    "\n",
    "    def level_of(sz: float):\n",
    "        r = sz / body_sz\n",
    "        if r >= 1.8:  return \"H1\"\n",
    "        if r >= 1.45: return \"H2\"\n",
    "        if r >= 1.20: return \"H3\"\n",
    "        if r >= 1.05: return \"H4\"\n",
    "        return None\n",
    "\n",
    "    # 3) Collect headings\n",
    "    raw = []\n",
    "    for pi, pg in enumerate(pages):\n",
    "        for ln in pg:\n",
    "            lvl = level_of(ln.size)\n",
    "            if not lvl: continue\n",
    "            # drop very long lines\n",
    "            if len(ln.text.split()) > 30: continue\n",
    "            raw.append(Heading(level=lvl, text=ln.text.strip(), page=pi+1))\n",
    "\n",
    "    # 4) Merge consecutive same-level headings\n",
    "    merged = []\n",
    "    for h in raw:\n",
    "        if merged and merged[-1].level == h.level and merged[-1].page == h.page:\n",
    "            # append text\n",
    "            merged[-1].text += \" \" + h.text\n",
    "        else:\n",
    "            merged.append(h)\n",
    "\n",
    "    # 5) Deduplicate exact repeats\n",
    "    final = []\n",
    "    seen = set()\n",
    "    for h in merged:\n",
    "        key = (h.level, h.text, h.page)\n",
    "        if key in seen: continue\n",
    "        seen.add(key)\n",
    "        final.append(h)\n",
    "\n",
    "    # 6) Assemble output\n",
    "    outline = {\n",
    "      \"title\": title_text,\n",
    "      \"outline\": [asdict(h) for h in final]\n",
    "    }\n",
    "    return outline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93993fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"RFP: R RFP: Re e equest f quest f quest fo o or Pr r Pr r Proposal oposal oposal RFP: R RFP: R e quest f o r Pr oposal\",\n",
      "  \"outline\": [\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"Ontario’s Libraries Working T ogether\",\n",
      "      \"page\": 1\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"T o Present a Proposal for Developing the Business Plan for the Ontario Digital Library March 21, 2003\",\n",
      "      \"page\": 1\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H1\",\n",
      "      \"text\": \"Ontario’s Digital Library\",\n",
      "      \"page\": 2\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H3\",\n",
      "      \"text\": \"A Critical Component for Implementing Ontario’s Road Map to Prosperity Strategy\",\n",
      "      \"page\": 2\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Summary\",\n",
      "      \"page\": 2\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Background\",\n",
      "      \"page\": 3\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"The Business Plan to be Developed\",\n",
      "      \"page\": 6\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Milestones Approach and Specific Proposal Requirements\",\n",
      "      \"page\": 7\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Evaluation and Awarding of Contract\",\n",
      "      \"page\": 8\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Appendix A:  ODL Envisioned Phases & Funding\",\n",
      "      \"page\": 9\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Funding Source 2007 2017\",\n",
      "      \"page\": 10\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Appendix B: ODL Steering Committee Terms of Reference\",\n",
      "      \"page\": 11\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \".\",\n",
      "      \"page\": 12\n",
      "    },\n",
      "    {\n",
      "      \"level\": \"H4\",\n",
      "      \"text\": \"Appendix C: ODL’s Envisioned Electronic Resources\",\n",
      "      \"page\": 14\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "✅  Saved: /Users/tanmayrath/Downloads/file03_outline.json\n"
     ]
    }
   ],
   "source": [
    "def save_outline(outline: Dict, pdf_path: str):\n",
    "    pdf_path = pathlib.Path(pdf_path).expanduser()\n",
    "    out_path = pdf_path.parent / f\"{pdf_path.stem}_outline.json\"   # ← fixed\n",
    "    out_path.write_text(json.dumps(outline, indent=2, ensure_ascii=False))\n",
    "    print(\"Saved:\", out_path)\n",
    "result = extract_outline(\"/Users/tanmayrath/Downloads/file03.pdf\")\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "save_outline(result, \"/Users/tanmayrath/Downloads/file03.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faea210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "outline": [
        {
         "level": "H3",
         "page": 1,
         "text": "Ontario’s Libraries Working T ogether"
        },
        {
         "level": "H1",
         "page": 1,
         "text": "T o Present a Proposal for Developing the Business Plan for the Ontario Digital Library March 21, 2003"
        },
        {
         "level": "H1",
         "page": 2,
         "text": "Ontario’s Digital Library"
        },
        {
         "level": "H3",
         "page": 2,
         "text": "A Critical Component for Implementing Ontario’s Road Map to Prosperity Strategy"
        },
        {
         "level": "H4",
         "page": 2,
         "text": "Summary"
        },
        {
         "level": "H4",
         "page": 3,
         "text": "Background"
        },
        {
         "level": "H4",
         "page": 6,
         "text": "The Business Plan to be Developed"
        },
        {
         "level": "H4",
         "page": 7,
         "text": "Milestones Approach and Specific Proposal Requirements"
        },
        {
         "level": "H4",
         "page": 8,
         "text": "Evaluation and Awarding of Contract"
        },
        {
         "level": "H4",
         "page": 9,
         "text": "Appendix A:  ODL Envisioned Phases & Funding"
        },
        {
         "level": "H4",
         "page": 10,
         "text": "Funding Source 2007 2017"
        },
        {
         "level": "H4",
         "page": 11,
         "text": "Appendix B: ODL Steering Committee Terms of Reference"
        },
        {
         "level": "H4",
         "page": 12,
         "text": "."
        },
        {
         "level": "H4",
         "page": 14,
         "text": "Appendix C: ODL’s Envisioned Electronic Resources"
        }
       ],
       "title": "RFP: R RFP: Re e equest f quest f quest fo o or Pr r Pr r Proposal oposal oposal RFP: R RFP: R e quest f o r Pr oposal"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import JSON, display\n",
    "display(JSON(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b423ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"full_outline.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c7efbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '._.DS_Store', 'images', '._images', 'annotations', '._annotations']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/Volumes/Extreme SSD/docbank_testing_data_gpu\"\n",
    "\n",
    "files = os.listdir(data_dir)\n",
    "print(files[:10])  # just print first 10 to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f386216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20.tar_1502.01891.gz_paper_16.json', '._20.tar_1502.01891.gz_paper_16.json', '2.tar_1701.00641.gz_StringMath16_arXiv_v2_24.json', '._2.tar_1701.00641.gz_StringMath16_arXiv_v2_24.json', '195.tar_1709.00813.gz_Satisfaction_Feature_Reduction_Paper_Presubmit_7.json']\n"
     ]
    }
   ],
   "source": [
    "annotation_path = os.path.join(data_dir, \"annotations\")\n",
    "ann_files = os.listdir(annotation_path)\n",
    "print(ann_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef8b6d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'text': 'Proof.', 'x0': 117, 'y0': 93, 'x1': 167, 'y1': 108, 'r': 0, 'g': 0, 'b': 0, 'font_name': 'JSMVHV+CMTI12', 'label': 'paragraph', 'box': [117, 93, 167, 108]}, {'text': 'Assume,', 'x0': 177, 'y0': 93, 'x1': 247, 'y1': 108, 'r': 0, 'g': 0, 'b': 0, 'font_name': 'BBNPKH+CMR12', 'label': 'paragraph', 'box': [177, 93, 247, 108]}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "json_file = os.path.join(annotation_path, '20.tar_1502.01891.gz_paper_16.json')\n",
    "\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Print first few keys/entries\n",
    "print(type(data))\n",
    "print(data.keys() if isinstance(data, dict) else data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c2f5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             text      label   x1  y1   x2   y2\n",
      "0          Proof.  paragraph  117  93  167  108\n",
      "1         Assume,  paragraph  177  93  247  108\n",
      "2              by  paragraph  252  93  272  108\n",
      "3  contradiction,  paragraph  276  93  391  108\n",
      "4            that  paragraph  396  93  431  108\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(annotation_path, '20.tar_1502.01891.gz_paper_16.json')\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add bbox as columns if needed\n",
    "if \"box\" in df.columns:\n",
    "    df[[\"x1\", \"y1\", \"x2\", \"y2\"]] = pd.DataFrame(df[\"box\"].tolist(), index=df.index)\n",
    "\n",
    "# Preview\n",
    "print(df[[\"text\", \"label\", \"x1\", \"y1\", \"x2\", \"y2\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2afefd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['197.tar_1709.01863.gz_On_the_geometry_133_ori.jpg', '._197.tar_1709.01863.gz_On_the_geometry_133_ori.jpg', '2.tar_1601.00582.gz_extrema_logrv_jan16_13_ori.jpg', '._2.tar_1601.00582.gz_extrema_logrv_jan16_13_ori.jpg', '20.tar_1602.01139.gz_jdcgs-tcom15_V15_SJ_4_ori.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_path = os.path.join(data_dir, \"images\")\n",
    "ann_files = os.listdir(image_path)\n",
    "print(ann_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a541b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# Load one image\n",
    "img_path = os.path.join(image_dir, image_files[0])\n",
    "img = Image.open(img_path)\n",
    "img.show()  # Will preview the image in a window (Mac Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3789a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering pages: 100%|██████████████████████████| 14/14 [00:01<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 14 images to /Volumes/Extreme SSD/AdobeIndiaHackathon/pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pdf_to_images_pymupdf.py\n",
    "# pip install pymupdf pillow tqdm\n",
    "\n",
    "import fitz                     # PyMuPDF\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image           # just for optional re-save to PNG/JPEG\n",
    "\n",
    "def pdf_to_images(pdf_path: str | Path,\n",
    "                  out_dir: str | Path = \"pages\",\n",
    "                  dpi: int = 200,\n",
    "                  fmt: str = \"png\") -> None:\n",
    "    pdf_path = Path(pdf_path).expanduser()\n",
    "    out_dir  = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    zoom = dpi / 72               # 72 dpi is the native PDF resolution\n",
    "    matrix = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "    for page_idx in tqdm(range(len(doc)), desc=\"Rendering pages\"):\n",
    "        pix = doc.load_page(page_idx).get_pixmap(matrix=matrix)\n",
    "        img_path = out_dir / f\"{pdf_path.stem}_page{page_idx+1}.{fmt}\"\n",
    "        pix.save(img_path)        # saves directly to PNG/JPEG/TIFF\n",
    "\n",
    "        # Optional post-processing with Pillow\n",
    "        # Image.open(img_path).convert(\"RGB\").save(img_path, quality=90)\n",
    "\n",
    "    print(f\"✓ Saved {len(doc)} images to {out_dir.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_to_images(\"/Users/tanmayrath/Downloads/file03.pdf\")   # ← replace with your PDF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wine ML",
   "language": "python",
   "name": "wine-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
